{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook is mostly continued in Additional Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"We analyzed data from 7,321 of the 11,878 participants. This subset resulted from the\n",
    "following exclusion, which attempted to eliminate incomplete data or data that were already\n",
    "flagged as problematic by the ABCD study organizers. First, we attempted to download 8,811\n",
    "participants from the “FastTrack Recommended Active Series” from the NIMH Data Archive,\n",
    "which has gone through some quality assurance for the associated imaging files by the ABCD\n",
    "study organizers. Of these, 8,776 files were successfully downloaded, but a subset did not\n",
    "include stop-signal data, leaving ​ 7,906 subjects. Of these, only 7,347 included ​ summary scores\n",
    "from the Stop Signal Task in the ABCD Data Release 2.0. Finally, 26 subjects were removed who did not have two complete runs with 180 trials each, leaving us with a total of 7,321\n",
    "complete datasets.\"\n",
    "\n",
    "The first issue to look into is the question of which subset of subjects the authors used and if the authors employed the provided behavioral perforance flags.\n",
    "\n",
    "This script is provided seperatly as I did not want to modify the chunk of the authors original code too much, so this script covers the computationally intensive part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8794"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# All I could download\n",
    "v1 = pd.read_csv('merged_data/all_concat.csv', low_memory=False)\n",
    "len(v1.src_subject_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8123"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# All .txt w/o any errors\n",
    "v2 = pd.read_csv('merged_data/SST_concat.csv', low_memory=False)\n",
    "len(v2.src_subject_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9598"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The release 2.0 summary csv, set summary_2_subjects as all subjects\n",
    "summary_2_df = pd.read_csv('/home/sage/work/ABCD2p0NDA/abcd_sst02.txt', sep='\\t', skiprows=[1])\n",
    "summary_2_subjects = pd.unique(summary_2_df.subjectkey)\n",
    "len(summary_2_subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8484"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alternately, set a smaller subset as those that pass the performance flag\n",
    "behav_flag_subjects = pd.unique(summary_2_df[summary_2_df['tfmri_sst_beh_performflag'] == 1].subjectkey)\n",
    "len(behav_flag_subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8180"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v3 = v1[v1['src_subject_id'].isin(summary_2_subjects)]\n",
    "len(v3.src_subject_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7550"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v4 = v2[v2['src_subject_id'].isin(summary_2_subjects)]\n",
    "len(v4.src_subject_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7228"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v5 = v1[v1['src_subject_id'].isin(behav_flag_subjects)]\n",
    "len(v5.src_subject_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6700"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v6 = v2[v2['src_subject_id'].isin(behav_flag_subjects)]\n",
    "len(v6.src_subject_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_SST_concat(df):\n",
    "    \n",
    "    incomplete_runs_subj = [] \n",
    "    SST_concat = pd.DataFrame()\n",
    "    incomplete_runs_df = pd.DataFrame()\n",
    "    df = df[np.logical_and(df.TrialCode != 'BeginFix', \\\n",
    "                           df.TrialCode != 'EndFix')]\n",
    "\n",
    "    df = df[~df['TrialCode'].isnull()]\n",
    "\n",
    "    for i in df['NARGUID'].unique(): \n",
    "        sub_df = df.loc[df['NARGUID'] == i]\n",
    "        #add TrialNum col from 1-360\n",
    "        sub_df['TrialNum'] = np.arange(1, len(sub_df)+1)\n",
    "        stop_trial_mask = (sub_df['TrialCode'] == 'IncorrectStop') | \\\n",
    "                          (sub_df['TrialCode'] == 'CorrectStop')\n",
    "        stop_trial_idx = stop_trial_mask[stop_trial_mask == True].index\n",
    "        sub_df['StopTrial'] = \"\"\n",
    "        sub_df['StopTrial'][stop_trial_idx] = np.arange(1, len(sub_df.loc[stop_trial_idx])+ 1)\n",
    "\n",
    "        if len(~sub_df['TrialNum'].isnull()) == 360: \n",
    "            if 'StopTooEarly' not in sub_df['TrialCode'].unique(): \n",
    "                SST_concat = SST_concat.append(sub_df)\n",
    "        else: \n",
    "            incomplete_runs_df = incomplete_runs_df.append(sub_df)\n",
    "            incomplete_runs_subj.append(i)\n",
    "            \n",
    "    return SST_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sage/anaconda3/envs/home/lib/python3.7/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/home/sage/anaconda3/envs/home/lib/python3.7/site-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/sage/anaconda3/envs/home/lib/python3.7/site-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/sage/anaconda3/envs/home/lib/python3.7/site-packages/pandas/core/series.py:1295: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._set_labels(key, value)\n",
      "/home/sage/anaconda3/envs/home/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "for i, v in enumerate([v1, v2, v3, v4, v5, v6]):\n",
    "    proced = get_SST_concat(v)\n",
    "    proced.to_csv('merged_data/' + str(i+1) + '_.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After running this for the 6 different versions, analysis continue in Additional Analysis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('home': conda)",
   "language": "python",
   "name": "python37664bithomeconda2aade2e1d0ce4797afe91f4891a59d68"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
