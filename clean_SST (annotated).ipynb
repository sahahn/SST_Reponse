{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an annotated version of the original script as found on https://github.com/mckenziephagen/ABCD_Stop_Signal\n",
    "Explcit comments will be made new code cells."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this takes in the raw E-Prime files, which have been concatonated together into one large file (raw_concat.csv), and does minimal processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this makes it so that the WHOLE dataframe prints, just fyi, this can bog down your code\n",
    "\n",
    "pd.set_option('display.max_columns', 1000)  # or 1000\n",
    "pd.set_option('display.max_rows', None)  # or 1000\n",
    "pd.set_option('display.max_colwidth', 199)  # or 199"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "############################################################################################################################\n",
    "\n",
    "\n",
    "The script begins assuming raw_concat has been loaded into memory. Replicating how the original authors constructed raw_concat from the fast track data was **Non-trivial**, and involved digging into deleted files from the authors github commit history, i.e., for downloading from fasttrack / determining what release they used / which subjects they tried to download: https://github.com/mckenziephagen/ABCD_Stop_Signal/blob/eaf3c8d500971ba8c458c59f743fd3040eeb1133/scripts/General/s3_keys.ipynb (Slight accidental public sharing on the last dataframe here). and\n",
    "\n",
    "For creating a merged concat file: \n",
    "https://github.com/mckenziephagen/ABCD_Stop_Signal/blob/eaf3c8d500971ba8c458c59f743fd3040eeb1133/scripts/SST_manuscript/concat.ipynb (Note the concat is only being performed on a subset of 100 subjects, so we had to assume either they corrected the mistakes they made in loading these 100 subjects, e.g., missing all event files coded as csv, handled errors related to differently formatted files, dealt with two exact copies of the eventfile being saved with each subject - or we have to assume they missed some/all of these issues - which is likely the case, as we assume they do not, and end up with ~700 more subjects.\n",
    "\n",
    "Of relevance is this section from their paper:\n",
    "\n",
    "\"Of these, 8,776 files were successfully downloaded, but a subset did not\n",
    "include stop-signal data, leaving ​ 7,906 subjects. Of these, only 7,347 included ​ summary scores\n",
    "from the Stop Signal Task in the ABCD Data Release 2.0. Finally, 26 subjects were removed who did not have two complete runs with 180 trials each, leaving us with a total of 7,321\n",
    "complete datasets.\"\n",
    "\n",
    "Which provided some aid in our efforts to replicate this process.\n",
    "\n",
    "#### Our full effort in replicating these steps can be found in 'Match Data.ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We make the assumption in this 'raw_concat' that they corrected all merging issues\n",
    "# which while erroneous should not lead to many issues\n",
    "raw_concat = pd.read_csv('merged_data/all_concat.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "############################################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "############################################################################################################################\n",
    "The below section of code was originally fully commented out at the time of the original bioarvix post https://github.com/mckenziephagen/ABCD_Stop_Signal/blob/e10d76332136b64cb6ed19a3da48f2bfd6121002/scripts/SST_manuscript/clean_SST.ipynb\n",
    "\n",
    "In the current version most of it is uncommented, but still they comment out the computation of the stop trial mask, and importantly the 'StopTrial' column (which they use heavily in SST_problems, and compute nowhere else but here. In light of its later usage... we will leave first the original code for reference, but run a version fo the code with the internal comments taken out (as they are later used). Based on further evidence from the order of the cells run, the author did not re-run this step after performing un-commenting (likely because it takes a long time to run...)\n",
    "\n",
    "As a general reccomendation, analysis code like this should strive to be 'easily rerfreshable', i.e., at certain points in the analysis one should just re-run everything if possible in order to make sure mistakes were not introduced (incredibly common in jupyter notebooks where cells can be run out of order). We understand why the author introduces non-linearities through intermediary save files, but suggest that 1st: potential optimizations be looked into (i.e., making it so the internal saved representations are not neccissary). In this case the most obvious optimization is that a merged dataframe with all subjects run information should not be used, almost all of these calculations are embarrasingly parrellel, which means they can easily be chunked and computed on a by subject basis - this would also likely reduce the complexity of the code in regards to simple operations.\n",
    "\n",
    "2nd: That even if intermediary save files are used, it should be clear how to create that saved file. I.e., if the initial logic leading up to the creation of incomplete_subjects.csv is put into functions, then only the code which calls the functions, ideally nested within another function, should be run. In that way, there can be one cell, which either calls to function to compute and save incomplete_subjects.csv, or that one line commented out and replaced with code to load incomplete_subjects.csv.\n",
    "\n",
    "**That said, with analysis like these, they are often done iteratively and in an exploratory fashion - which makes any lack of optimizations highly understandable!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Original ##\n",
    "\n",
    "incomplete_runs_subj = [] \n",
    "SST_concat = pd.DataFrame()\n",
    "incomplete_runs_df = pd.DataFrame()\n",
    "raw_concat = raw_concat[np.logical_and(raw_concat.TrialCode != 'BeginFix', \\\n",
    "                                       raw_concat.TrialCode != 'EndFix')]\n",
    "\n",
    "raw_concat = raw_concat[~raw_concat['TrialCode'].isnull()]\n",
    "\n",
    "for i in raw_concat['NARGUID'].unique(): \n",
    "    sub_df = raw_concat.loc[raw_concat['NARGUID'] == i]\n",
    "    #add TrialNum col from 1-360\n",
    "    sub_df['TrialNum'] = np.arange(1, len(sub_df)+1)\n",
    "#     stop_trial_mask = (sub_df['TrialCode'] == 'IncorrectStop') | \\\n",
    "#                       (sub_df['TrialCode'] == 'CorrectStop')\n",
    "#     stop_trial_idx = stop_trial_mask[stop_trial_mask == True].index\n",
    "#     sub_df['StopTrial'] = \"\"\n",
    "#     sub_df['StopTrial'][stop_trial_idx] = np.arange(1, len(sub_df.loc[stop_trial_idx])+ 1)\n",
    "    if len(~sub_df['TrialNum'].isnull()) == 360: \n",
    "        if 'StopTooEarly' not in sub_df['TrialCode'].unique(): \n",
    "            SST_concat = SST_concat.append(sub_df)\n",
    "    else: \n",
    "        incomplete_runs_df = incomplete_runs_df.append(sub_df)\n",
    "        incomplete_runs_subj.append(i)\n",
    "    \n",
    "\n",
    "incomplete_runs_df.to_csv('incomplete_subjects.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Original ##\n",
    "\n",
    "#this saves as a csv so you can avoid running that loops multiple times \n",
    "#SST_concat.to_csv('reran_partially_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sage/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/home/sage/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/sage/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/sage/anaconda3/lib/python3.6/site-packages/pandas/core/series.py:1092: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._set_labels(key, value)\n",
      "/home/sage/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3331: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "## modfied\n",
    "\n",
    "incomplete_runs_subj = [] \n",
    "SST_concat = pd.DataFrame()\n",
    "incomplete_runs_df = pd.DataFrame()\n",
    "raw_concat = raw_concat[np.logical_and(raw_concat.TrialCode != 'BeginFix', \\\n",
    "                                       raw_concat.TrialCode != 'EndFix')]\n",
    "\n",
    "raw_concat = raw_concat[~raw_concat['TrialCode'].isnull()]\n",
    "\n",
    "for i in raw_concat['NARGUID'].unique(): \n",
    "    sub_df = raw_concat.loc[raw_concat['NARGUID'] == i]\n",
    "    #add TrialNum col from 1-360\n",
    "    sub_df['TrialNum'] = np.arange(1, len(sub_df)+1)\n",
    "    stop_trial_mask = (sub_df['TrialCode'] == 'IncorrectStop') | \\\n",
    "                      (sub_df['TrialCode'] == 'CorrectStop')\n",
    "    stop_trial_idx = stop_trial_mask[stop_trial_mask == True].index\n",
    "    sub_df['StopTrial'] = \"\"\n",
    "    sub_df['StopTrial'][stop_trial_idx] = np.arange(1, len(sub_df.loc[stop_trial_idx])+ 1)\n",
    "    \n",
    "    if len(~sub_df['TrialNum'].isnull()) == 360: \n",
    "        if 'StopTooEarly' not in sub_df['TrialCode'].unique(): \n",
    "            SST_concat = SST_concat.append(sub_df)\n",
    "    else: \n",
    "        incomplete_runs_df = incomplete_runs_df.append(sub_df)\n",
    "        incomplete_runs_subj.append(i)\n",
    "\n",
    "incomplete_runs_df.to_csv('incomplete_subjects.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## modfied\n",
    "\n",
    "#this saves as a csv so you can avoid running that loops multiple times \n",
    "SST_concat.to_csv('merged_data/reran_partially_cleaned.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While obnoxious, the SettingWithCopyWarning is a general indicator of bad practices. In this case it is inconsequential - but it arises from this line sub_df = raw_concat.loc[raw_concat['NARGUID'] == i],\n",
    "what happens is that the author grabs a view of the original raw_concat dataframe for just one unique subject, and then modifies that view. All the error is saying is that these changes to value likely are not being made on the original raw_concat, which is not technically a problem as the author simply creates a new dataframe (albiet, in a very ineffecient manner - it is considered poor practice to call keep appending to a dataframe as one would a python list, as pandas append operation creates a new copy everytime see:\n",
    "\n",
    "\"Iteratively appending rows to a DataFrame can be more computationally intensive than a single concatenate. A better solution is to append those rows to a list and then concatenate the list with the original DataFrame all at once.\" - https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.append.html\n",
    "\n",
    "Likewise, an even more effecient solution would operate with still every subjects data stored seperately as mentioned before.\n",
    "\n",
    "While these concerns as mentioned in this cell do not directly effect the integrity of the results, they are  related to the ease of replicability of the code. I.e., if it takes someone a long time to run a chunk of code, and they have to back-track and de-cipher the origins of where saved csv's were made, and where raw_concat comes from, it increases the burden of replication and serves to unintentionally obscificate the entire analysis.\n",
    "############################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this reads in the file above, to avoid running that loop \n",
    "SST_concat = pd.read_csv('merged_data/reran_partially_cleaned.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check \"TrialCode\" accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sage/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py:670: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "#some subjects have their subtrial under Procedure[Trial]\n",
    "SST_concat['Procedure[SubTrial]'].loc[SST_concat['Procedure[SubTrial]'].isnull()] = SST_concat['Procedure[Trial]'] \n",
    "#the trial type column has inconsistent notation for stop trials \n",
    "SST_concat['trial_type'] = SST_concat['Procedure[SubTrial]'].replace('VariableStopTrial.*', 'StopTrial', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find all go trials \n",
    "go_trial_mask = SST_concat.loc[SST_concat['Procedure[SubTrial]'] == 'GoTrial']\n",
    "go_trial_idx = go_trial_mask[go_trial_mask==True].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the response recordings are inconsistent in type (str, int, float) this fixes that \n",
    "cresp_replace = {'2.0': 2.0,\n",
    "                 '1.0': 1.0,\n",
    "                 '3.0': 3.0,\n",
    "                 '4.0': 4.0,\n",
    "                 '1,{LEFTARROW}': 1.0,\n",
    "                 '2,{RIGHTARROW}': 2.0}\n",
    "\n",
    "resp_replace = {'2.0': 2.0,\n",
    "                '1.0': 1.0,\n",
    "                '3.0': 3.0,\n",
    "                '4.0': 4.0,\n",
    "                '{LEFTARROW}': 1.0,\n",
    "                '{RIGHTARROW}': 2.0}\n",
    "\n",
    "SST_concat['Go.RESP'].replace(to_replace = resp_replace, inplace=True)\n",
    "SST_concat['Go.CRESP'].replace(to_replace = cresp_replace, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.0 3.0 nan 1.0 2.0 '1' '2'] [ 4.  3. nan  1.  2.]\n",
      "[ 4.  3. nan  1.  2.] [ 4.  3. nan  1.  2.]\n"
     ]
    }
   ],
   "source": [
    "# New / Added, cast to float - one reason I might be having to do these additional casts\n",
    "# is I loaded the initial dataframe in w/ low_memory_mode set to False, where perhaps the original\n",
    "# author did not\n",
    "print(SST_concat['Go.RESP'].unique(), SST_concat['Go.CRESP'].unique())\n",
    "\n",
    "SST_concat['Go.RESP'] = SST_concat['Go.RESP'].astype(float)\n",
    "SST_concat['Go.CRESP'] = SST_concat['Go.CRESP'].astype(float)\n",
    "\n",
    "print(SST_concat['Go.RESP'].unique(), SST_concat['Go.CRESP'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan 4.0 3.0 2.0 1.0 '4.0' '3.0' '1.0' '2.0' '{RIGHTARROW}' '{LEFTARROW}'\n",
      " '2' '1'] [nan 4.0 3.0 1.0 2.0 '4.0' '3.0' '1.0' '2.0' '{RIGHTARROW}' '{LEFTARROW}'] [nan 3.0 1.0 2.0 4.0 '3.0' '4.0' '1.0' '2.0' '{LEFTARROW}' '{RIGHTARROW}']\n",
      "[nan  4.  3.  2.  1.] [nan  4.  3.  1.  2.] [nan  3.  1.  2.  4.]\n"
     ]
    }
   ],
   "source": [
    "# New / added check stop responses for same error\n",
    "print(SST_concat['Fix.RESP'].unique(), SST_concat['StopSignal.RESP'].unique(), SST_concat['SSD.RESP'].unique())\n",
    "\n",
    "# And fix\n",
    "SST_concat['Fix.RESP'].replace(to_replace=resp_replace, inplace=True)\n",
    "SST_concat['Fix.RESP'] = SST_concat['Fix.RESP'].astype(float)\n",
    "\n",
    "SST_concat['StopSignal.RESP'].replace(to_replace=resp_replace, inplace=True)\n",
    "SST_concat['StopSignal.RESP'] = SST_concat['StopSignal.RESP'].astype(float)\n",
    "\n",
    "SST_concat['SSD.RESP'].replace(to_replace=resp_replace, inplace=True)\n",
    "SST_concat['SSD.RESP'] = SST_concat['SSD.RESP'].astype(float)\n",
    "\n",
    "print(SST_concat['Fix.RESP'].unique(), SST_concat['StopSignal.RESP'].unique(), SST_concat['SSD.RESP'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create my own correct response column \n",
    "SST_concat['correct_go_response'] = np.NaN\n",
    "\n",
    "SST_concat['correct_go_response'].loc[(~SST_concat['Go.RESP'].isnull()) & \n",
    "                                      (SST_concat['Go.CRESP'] == SST_concat['Go.RESP'])] = float(1)\n",
    "\n",
    "SST_concat['correct_go_response'].loc[(SST_concat['Go.RESP'].isnull()) & \n",
    "                                      (SST_concat['Go.CRESP'] == SST_concat['Fix.RESP'])] = float(1)\n",
    "\n",
    "SST_concat['correct_go_response'].loc[(~SST_concat['Go.RESP'].isnull()) & \n",
    "                                      (SST_concat['Go.CRESP'] != SST_concat['Go.RESP']) &\n",
    "                                      (SST_concat['trial_type'] == 'GoTrial')] = float(0)\n",
    "\n",
    "\n",
    "SST_concat['correct_go_response'].loc[(SST_concat['Go.RESP'].isnull()) & \n",
    "                                      (SST_concat['Go.CRESP'] != SST_concat['Fix.RESP']) &\n",
    "                                      (SST_concat['trial_type'] == 'GoTrial')] = float(0)\n",
    "\n",
    "\n",
    "SST_concat['correct_go_response'].loc[(SST_concat['Go.RESP'].isnull()) & (SST_concat['Fix.RESP'].isnull()) & \n",
    "                                      (SST_concat['trial_type'] == 'GoTrial')] = 'omission'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.0, 0.0, 'omission'], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check that I only have ones, zeros, and omissions\n",
    "SST_concat.loc[SST_concat['trial_type'] == 'GoTrial']['correct_go_response'].unique() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#correct stop column \n",
    "SST_concat['correct_stop'] = np.NaN\n",
    "\n",
    "SST_concat['correct_stop'].loc[(SST_concat['StopSignal.RESP'].isnull()) & (SST_concat['Fix.RESP'].isnull()) & \\\n",
    "                               (SST_concat['trial_type'] == 'StopTrial') & (SST_concat['SSD.RESP'].isnull())] = float(1)\n",
    "\n",
    "SST_concat['correct_stop'].loc[(~(SST_concat['StopSignal.RESP'].isnull()) | ~(SST_concat['Fix.RESP'].isnull()) \\\n",
    "                                | ~(SST_concat['SSD.RESP'].isnull())) & (SST_concat['trial_type'] == 'StopTrial')] = float(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "SST_concat['correct_stimulus_mapping_1'] = np.NaN\n",
    "SST_concat['correct_stimulus_mapping_2'] = np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "SST_concat.loc[SST_concat['Stimulus'] == 'images/Right_Arrow.bmp', 'correct_stimulus_mapping_1'] = SST_concat.loc[SST_concat['Stimulus'] == 'images/Right_Arrow.bmp']['Go.CRESP'].dropna().unique()[0]\n",
    "SST_concat.loc[SST_concat['Stimulus'] == 'images/Right_Arrow.bmp', 'correct_stimulus_mapping_2'] = SST_concat.loc[SST_concat['Stimulus'] == 'images/Right_Arrow.bmp']['Go.CRESP'].dropna().unique()[1]\n",
    "\n",
    "SST_concat.loc[SST_concat['Stimulus'] == 'images/Left_Arrow.bmp', 'correct_stimulus_mapping_1'] = SST_concat.loc[SST_concat['Stimulus'] == 'images/Left_Arrow.bmp']['Go.CRESP'].dropna().unique()[0]\n",
    "SST_concat.loc[SST_concat['Stimulus'] == 'images/Left_Arrow.bmp', 'correct_stimulus_mapping_2'] = SST_concat.loc[SST_concat['Stimulus'] == 'images/Left_Arrow.bmp']['Go.CRESP'].dropna().unique()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0\n",
      "2.0\n",
      "4.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# New / added\n",
    "print(SST_concat.loc[SST_concat['Stimulus'] == 'images/Right_Arrow.bmp']['Go.CRESP'].dropna().unique()[0])\n",
    "print(SST_concat.loc[SST_concat['Stimulus'] == 'images/Right_Arrow.bmp']['Go.CRESP'].dropna().unique()[1])\n",
    "print(SST_concat.loc[SST_concat['Stimulus'] == 'images/Left_Arrow.bmp']['Go.CRESP'].dropna().unique()[0])\n",
    "print(SST_concat.loc[SST_concat['Stimulus'] == 'images/Left_Arrow.bmp']['Go.CRESP'].dropna().unique()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#correct stop choice response \n",
    "SST_concat['correct_stop_mapping'] = np.NaN \n",
    "SST_concat['correct_stop_mapping'].loc[(SST_concat['correct_stop'] == 0) & (~SST_concat['SSD.RESP'].isnull()) &\\\n",
    "                                       ((SST_concat['SSD.RESP'] == SST_concat['correct_stimulus_mapping_1']) | (SST_concat['SSD.RESP'] == SST_concat['correct_stimulus_mapping_2']))] = float(1)\n",
    "\n",
    "SST_concat['correct_stop_mapping'].loc[(SST_concat['correct_stop'] == 0) & (~SST_concat['SSD.RESP'].isnull()) &\\\n",
    "                                      (SST_concat['SSD.RESP'] != SST_concat['correct_stimulus_mapping_1']) & (SST_concat['SSD.RESP'] != SST_concat['correct_stimulus_mapping_2'])] = float(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "SST_concat['correct_stop_mapping'].loc[(SST_concat['correct_stop'] == 0) & (SST_concat['SSD.RESP'].isnull()) & (~SST_concat['StopSignal.RESP'].isnull()) &\\\n",
    "                                       ((SST_concat['StopSignal.RESP'] == SST_concat['correct_stimulus_mapping_1']) | (SST_concat['StopSignal.RESP'] == SST_concat['correct_stimulus_mapping_2']))] = float(1)\n",
    "\n",
    "SST_concat['correct_stop_mapping'].loc[(SST_concat['correct_stop'] == 0) & (SST_concat['SSD.RESP'].isnull()) & (~SST_concat['StopSignal.RESP'].isnull()) &\\\n",
    "                                       ((SST_concat['StopSignal.RESP'] != SST_concat['correct_stimulus_mapping_1']) & (SST_concat['StopSignal.RESP'] != SST_concat['correct_stimulus_mapping_2']))] = float(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "SST_concat['correct_stop_mapping'].loc[(SST_concat['correct_stop'] == 0) & (SST_concat['SSD.RESP'].isnull()) & (SST_concat['StopSignal.RESP'].isnull()) & (~SST_concat['Fix.RESP'].isnull()) &\\\n",
    "                                       ((SST_concat['Fix.RESP'] == SST_concat['correct_stimulus_mapping_1']) | (SST_concat['Fix.RESP'] == SST_concat['correct_stimulus_mapping_2']))] = float(1)\n",
    "\n",
    "SST_concat['correct_stop_mapping'].loc[(SST_concat['correct_stop'] == 0) & (SST_concat['SSD.RESP'].isnull()) & (SST_concat['StopSignal.RESP'].isnull()) & (~SST_concat['Fix.RESP'].isnull()) &\\\n",
    "                                       ((SST_concat['Fix.RESP'] != SST_concat['correct_stimulus_mapping_1']) & (SST_concat['Fix.RESP'] != SST_concat['correct_stimulus_mapping_2']))] = float(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fix the go.rt calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "since the trial unfolds over several different sub trials, it's necessary to add some of these together to get correct rt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the index of where there's a fixation response on go trials \n",
    "go_fix_resp = (~SST_concat['Fix.RESP'].isnull()) & \\\n",
    "              (SST_concat['Go.RESP'].isnull()) & \\\n",
    "              (SST_concat['trial_type'] == 'GoTrial')\n",
    "go_fix_idx = go_fix_resp[go_fix_resp == True].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sage/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "#make column from Go.RT values\n",
    "SST_concat['go_rt_adjusted'] = SST_concat['Go.RT'].copy()\n",
    "#for long response trials, add the fix.rt to the go.duration\n",
    "SST_concat['go_rt_adjusted'][go_fix_idx] = SST_concat.loc[go_fix_idx]['Go.Duration'] +  \\\n",
    "                                           SST_concat.loc[go_fix_idx]['Fix.RT']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### fix the stop sig rt calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find all stop trials\n",
    "stop_trial_mask = (SST_concat['trial_type'] == 'StopTrial')\n",
    "#make an index of all stop trials \n",
    "stop_trial_idx = stop_trial_mask[stop_trial_mask == True].index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "############################################################################################################################\n",
    "\n",
    "A few problems with the below calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Original\n",
    "\n",
    "SST_concat['stop_rt_adjusted'] = SST_concat['StopSignal.RT']\n",
    "#find all stop failure trials with resp during fix.resp, and no resp during stopsignal.resp\n",
    "stop_fix_resp = (~SST_concat['Fix.RESP'].isnull()) & \\\n",
    "                (SST_concat['StopSignal.RESP'].isnull()) & \\\n",
    "                ((SST_concat['trial_type'] == 'StopTrial') & SST_concat['correct_stop'] == 0)\n",
    "\n",
    "stop_fix_idx = stop_fix_resp[stop_fix_resp == True].index\n",
    "\n",
    "stop_SSD_resp = (~SST_concat['SSD.RESP'].isnull()) & \\\n",
    "                (~(SST_concat['StopSignal.RESP'].isnull()) | ~(SST_concat['Fix.RESP'].isnull()) \\\n",
    "                    | ~(SST_concat['SSD.RESP'].isnull()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original trues 246516\n",
      "last line trues 2783795\n",
      "fixed last line trues 248435\n",
      "stop fix resp fixed trues 52569\n"
     ]
    }
   ],
   "source": [
    "## New / added\n",
    "\n",
    "print('original trues', np.sum(stop_fix_resp))\n",
    "\n",
    "last_line = (SST_concat['trial_type'] == 'StopTrial') & SST_concat['correct_stop'] == 0\n",
    "print('last line trues', np.sum(last_line))\n",
    "\n",
    "what_it_should_be = ((SST_concat['trial_type'] == 'StopTrial') & (SST_concat['correct_stop'] == 0))\n",
    "print('fixed last line trues', np.sum(what_it_should_be))\n",
    "\n",
    "true_stop_fix_resp = (~SST_concat['Fix.RESP'].isnull()) & \\\n",
    "                (SST_concat['StopSignal.RESP'].isnull()) & \\\n",
    "                ((SST_concat['trial_type'] == 'StopTrial') & (SST_concat['correct_stop'] == 0))\n",
    "print('stop fix resp fixed trues', np.sum(true_stop_fix_resp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The calculation of stop_fix_resp has a programming error, misuse of brackets, that does not actually apply the condition that the trial type be a stop trial or that correct_stop be == 0. By potentially coincidence problems seem to have been avoided, i.e., in the next calculation this mask is used to add StopSignal.Duration and Fix.RT, st. by all of the extra Trues in the mask, they also have a StopSignal.Duration of NaN, so NaN + a number == NaN in pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## New / added\n",
    "\n",
    "stop_SSD_resp = (~SST_concat['SSD.RESP'].isnull()) & \\\n",
    "                (~(SST_concat['StopSignal.RESP'].isnull()) | ~(SST_concat['Fix.RESP'].isnull()) \\\n",
    "                    | ~(SST_concat['SSD.RESP'].isnull()))\n",
    "\n",
    "(stop_SSD_resp == ~SST_concat['SSD.RESP'].isnull()).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "stop_SSD_resp can be logically reduced to if 'SSD.RESP' is not null, i.e.,\n",
    "A and (B or C or A) == A, via formal logic.\n",
    "\n",
    "Not sure what their actual intention was, so I am not sure how to fix it.\n",
    "############################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sage/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/sage/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "#use that index to add stop signal duration to get correct stop signal RT on these trials\n",
    "SST_concat['stop_rt_adjusted'][stop_fix_resp] = SST_concat.loc[stop_fix_resp]['StopSignal.Duration'] +\\\n",
    "                                                SST_concat.loc[stop_fix_resp]['Fix.RT']\n",
    "\n",
    "SST_concat['stop_rt_adjusted'][stop_SSD_resp] = SST_concat.loc[stop_SSD_resp]['SSD.RT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sage/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## New / added\n",
    "\n",
    "# Confirm bad calc of stop_fix mask doesnt change anything\n",
    "\n",
    "SST_concat['alt_stop_rt'] = SST_concat['stop_rt_adjusted']\n",
    "\n",
    "SST_concat['alt_stop_rt'][true_stop_fix_resp] = SST_concat.loc[true_stop_fix_resp]['StopSignal.Duration'] +\\\n",
    "                                                SST_concat.loc[true_stop_fix_resp]['Fix.RT']\n",
    "\n",
    "np.sum(SST_concat['alt_stop_rt'][true_stop_fix_resp] != np.nan) == np.sum(~SST_concat['stop_rt_adjusted'][stop_fix_resp].isnull())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "############################################################################################################################\n",
    "\n",
    "A large conceptual error is made below. The stop_resp_mask is created w/ SSD.RESP included, and then SSDDur added.\n",
    "Clearly the SSDDur should not be added to SSD responses, this would be the equivilent of adding the full Go duration to all Go response times...\n",
    "\n",
    "A brief note on code style too, by defining the pandas column stop_rt_adjusted in a different cell, it means if this cell were run multiple times, the 'stop_rt_adjusted' would continue to increment higher and higher... not that I did this or anything (I did)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sage/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "## Original\n",
    "\n",
    "#find the stop failure trials and add the stop signal duration for correct stop fail RT\n",
    "stop_resp_mask = ((~(SST_concat['StopSignal.RESP'].isnull()) | ~(SST_concat['Fix.RESP'].isnull()) \\\n",
    "                                | ~(SST_concat['SSD.RESP'].isnull())) & \\\n",
    "                (~SST_concat['stop_rt_adjusted'].isnull()))\n",
    "        \n",
    "stop_resp_idx = stop_resp_mask[stop_resp_mask == True].index\n",
    "\n",
    "SST_concat['stop_rt_adjusted'][stop_resp_idx] = \\\n",
    "        SST_concat['stop_rt_adjusted'][stop_resp_idx] + SST_concat['SSDDur'][stop_resp_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_stop_resp_mask = ((~(SST_concat['StopSignal.RESP'].isnull()) | ~(SST_concat['Fix.RESP'].isnull())) & \\\n",
    "                      (~SST_concat['stop_rt_adjusted'].isnull()))\n",
    "true_stop_resp_idx = true_stop_resp_mask[true_stop_resp_mask == True].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26106"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(~(SST_concat['SSD.RESP'].isnull()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "20k+ is a lot of trials to have artificially inflated. We will note the impact on the original authors claims later on.\n",
    "\n",
    "We will re-create a fixed stop_rt_adjusted below, to compare with later on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sage/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/sage/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/home/sage/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "SST_concat['true_stop_rt_adjusted'] = SST_concat['StopSignal.RT']\n",
    "SST_concat['true_stop_rt_adjusted'][true_stop_fix_resp] =\\\n",
    "    SST_concat.loc[true_stop_fix_resp]['StopSignal.Duration'] + SST_concat.loc[true_stop_fix_resp]['Fix.RT']\n",
    "SST_concat['true_stop_rt_adjusted'][stop_SSD_resp] = SST_concat.loc[stop_SSD_resp]['SSD.RT']\n",
    "\n",
    "SST_concat['true_stop_rt_adjusted'][true_stop_resp_idx] =\\\n",
    "    SST_concat['true_stop_rt_adjusted'][true_stop_resp_idx] + SST_concat['SSDDur'][true_stop_resp_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(220.1271249950696, 235.56405553583403)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.nanmean(SST_concat['true_stop_rt_adjusted']), np.nanmean(SST_concat['stop_rt_adjusted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(449.24474409805384, 480.7517781311007)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(SST_concat[SST_concat['correct_stop'] == 0]['true_stop_rt_adjusted']), np.mean(SST_concat[SST_concat['correct_stop'] == 0]['stop_rt_adjusted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(~SST_concat['true_stop_rt_adjusted'].isnull()) == np.sum(~SST_concat['stop_rt_adjusted'].isnull())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "############################################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create go stimuli duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create column for Go.Stim.Duration - when there's no go response, this should be 1000ms\n",
    "SST_concat['go_stim_duration'] = SST_concat['Go.RT'].copy()\n",
    "SST_concat['go_stim_duration'].loc[SST_concat['Go.RT'] == 0] = SST_concat['Go.Duration'].loc[SST_concat['Go.RT'] == 0]\n",
    "\n",
    "SST_concat['go_stim_duration'].loc[~(SST_concat['SSD.RESP'].isnull())] = SST_concat.loc[~SST_concat['SSD.RESP'].isnull()]['SSD.RT']\n",
    "SST_concat['go_stim_duration'].loc[(SST_concat['SSD.RT']  == 0)] = SST_concat.loc[SST_concat['SSD.RT'] == 0]['SSDDur']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this saves it to csvs that are small enough to be viewed by excel\n",
    "#SST_concat.iloc[:867600].to_csv('SST_cleaned_7231_1.csv')\n",
    "#SST_concat.iloc[867600:1735560, :].to_csv('SST_cleaned_7231_2.csv')\n",
    "#SST_concat.iloc[1735560:].to_csv('SST_cleaned_7231_3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "SST_concat.to_csv('merged_data/SST_cleaned_7231_all_rows_all_columns.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
